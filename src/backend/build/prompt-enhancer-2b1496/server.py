"""MCP server for enhancing and optimizing prompts for various AI models and use cases
Generated by mcpgen. Server: prompt-enhancer
"""
from __future__ import annotations
from typing import Any, List, Dict, Optional
from mcp.server.fastmcp import FastMCP

mcp = FastMCP("prompt-enhancer", log_level="ERROR")



class GeneratedToolset:
    _tool_names: tuple[str, ...] = ("enhance_prompt", "add_examples", "add_constraints", "create_chain_of_thought", "optimize_for_context_window",)

    def __iter__(self):
        for name in self._tool_names:
            yield getattr(self, name)

    def enhance_prompt(self, prompt: str = None, target_model: str = 'general', style: str = 'detailed') -> Dict[str, str]:
        import re
        
        # Base enhancement templates
        templates = {
            'detailed': 'Context: {context}\n\nTask: {task}\n\nRequirements:\n{requirements}\n\nOutput Format: {format}',
            'concise': '{task} Specifically: {specifics}',
            'creative': 'Imagine: {context}\n\nYour creative challenge: {task}\n\nStyle notes: {style_notes}',
            'technical': 'Objective: {task}\n\nConstraints: {constraints}\n\nExpected Output: {output}\n\nAcceptance Criteria: {criteria}'
        }
        
        # Extract key components from original prompt
        prompt_lower = prompt.lower()
        
        # Identify task
        task = prompt
        if 'please' in prompt_lower:
            task = re.sub(r'please\s+', '', prompt, flags=re.IGNORECASE)
        
        # Add model-specific optimizations
        model_tips = {
            'gpt': 'Be clear and specific. ',
            'claude': 'Provide context and examples. ',
            'llama': 'Use structured format. ',
            'general': ''
        }
        
        # Build enhanced prompt based on style
        if style == 'detailed':
            enhanced = templates['detailed'].format(
                context='Working with: ' + target_model + ' model',
                task=task,
                requirements='- Be specific and actionable\n- Provide clear output',
                format='Structured response with clear sections'
            )
        elif style == 'concise':
            enhanced = templates['concise'].format(
                task=task.split('.')[0] if '.' in task else task,
                specifics='with clear, actionable output'
            )
        elif style == 'creative':
            enhanced = templates['creative'].format(
                context='a scenario where expertise meets creativity',
                task=task,
                style_notes='Be innovative while maintaining clarity'
            )
        else:  # technical
            enhanced = templates['technical'].format(
                task=task,
                constraints='Accuracy, clarity, and completeness',
                output='Well-structured, technically sound response',
                criteria='Correctness, completeness, and clarity'
            )
        
        # Add model-specific prefix
        enhanced = model_tips.get(target_model, '') + enhanced
        
        return {
            'original': prompt,
            'enhanced': enhanced.strip(),
            'style': style,
            'target_model': target_model
        }

    def add_examples(self, prompt: str = None, num_examples: int = 2) -> str:
        # Detect prompt type and add relevant examples
        prompt_lower = prompt.lower()
        
        # Limit examples
        num_examples = min(max(num_examples, 1), 3)
        
        examples = []
        
        if any(word in prompt_lower for word in ['write', 'create', 'generate', 'compose']):
            examples = [
                'Example: If asked to write about technology, provide a balanced view with specific innovations and impacts.',
                'Example: When creating content, use clear structure with introduction, body, and conclusion.',
                'Example: Generate text that is engaging, informative, and appropriate for the target audience.'
            ]
        elif any(word in prompt_lower for word in ['analyze', 'evaluate', 'assess', 'review']):
            examples = [
                'Example: Analysis should include key points, supporting evidence, and logical conclusions.',
                'Example: Evaluation should consider multiple perspectives and provide balanced judgment.',
                'Example: Assessment should be systematic, covering all relevant aspects thoroughly.'
            ]
        elif any(word in prompt_lower for word in ['explain', 'describe', 'clarify', 'define']):
            examples = [
                'Example: Explanations should progress from simple to complex, using clear language.',
                'Example: Descriptions should be vivid and specific, helping readers visualize concepts.',
                'Example: Definitions should be precise, with context and practical applications.'
            ]
        elif any(word in prompt_lower for word in ['list', 'enumerate', 'outline', 'summarize']):
            examples = [
                'Example: Lists should be organized logically with consistent formatting.',
                'Example: Outlines should show clear hierarchy and relationships between points.',
                'Example: Summaries should capture key points concisely while maintaining accuracy.'
            ]
        else:
            examples = [
                'Example: Provide specific, actionable responses.',
                'Example: Include relevant details and context.',
                'Example: Ensure clarity and completeness in your response.'
            ]
        
        # Select requested number of examples
        selected_examples = examples[:num_examples]
        
        # Format the enhanced prompt
        enhanced = prompt.rstrip('.')
        enhanced += '.\n\n' + '\n'.join(selected_examples)
        
        return enhanced

    def add_constraints(self, prompt: str = None, word_limit: int = 0, format_type: str = 'paragraph', tone: str = 'formal') -> str:
        # Build constraints section
        constraints = []\n    
        if word_limit > 0:
            constraints.append(f'Word limit: {word_limit} words')
        
        # Format specifications
        format_specs = {
            'paragraph': 'Use clear paragraphs with proper transitions',
            'bullet': 'Format as bullet points (- item)',
            'numbered': 'Format as numbered list (1. item)',
            'json': 'Return valid JSON format',
            'markdown': 'Use Markdown formatting with headers and emphasis'
        }
        
        if format_type in format_specs:
            constraints.append(f'Format: {format_specs[format_type]}')
        
        # Tone specifications
        tone_specs = {
            'formal': 'Use professional, formal language',
            'casual': 'Use conversational, friendly tone',
            'technical': 'Use precise technical terminology',
            'creative': 'Use engaging, creative expression'
        }
        
        if tone in tone_specs:
            constraints.append(f'Tone: {tone_specs[tone]}')
        
        # Additional standard constraints
        constraints.extend([
            'Be accurate and factual',
            'Provide complete information',
            'Maintain consistency throughout'
        ])
        
        # Format the enhanced prompt
        enhanced = prompt.rstrip('.')
        enhanced += '.\n\nConstraints and Requirements:\n'
        enhanced += '\n'.join(f'- {c}' for c in constraints)
        
        return enhanced

    def create_chain_of_thought(self, prompt: str = None, steps: int = 3) -> str:
        # Limit steps to reasonable range
        steps = min(max(steps, 2), 5)
        
        # Create chain-of-thought template
        cot_prompt = f'{prompt}\n\nLet\'s approach this step-by-step:\n\n'
        
        # Generate step descriptions based on prompt content
        prompt_lower = prompt.lower()
        
        if any(word in prompt_lower for word in ['solve', 'calculate', 'compute', 'math']):
            step_templates = [
                'Step 1: Identify the given information and what we need to find',
                'Step 2: Determine the appropriate method or formula',
                'Step 3: Apply the method systematically',
                'Step 4: Verify the solution for correctness',
                'Step 5: Present the final answer with units if applicable'
            ]
        elif any(word in prompt_lower for word in ['analyze', 'evaluate', 'compare']):
            step_templates = [
                'Step 1: Identify key components or criteria',
                'Step 2: Examine each component in detail',
                'Step 3: Compare and contrast findings',
                'Step 4: Synthesize insights',
                'Step 5: Draw conclusions'
            ]
        elif any(word in prompt_lower for word in ['write', 'create', 'generate']):
            step_templates = [
                'Step 1: Understand the requirements and audience',
                'Step 2: Outline the main points or structure',
                'Step 3: Develop each section with details',
                'Step 4: Review for coherence and flow',
                'Step 5: Polish and finalize'
            ]
        else:
            step_templates = [
                'Step 1: Understand the core question or task',
                'Step 2: Gather relevant information',
                'Step 3: Process and organize the information',
                'Step 4: Formulate the response',
                'Step 5: Review and refine the answer'
            ]
        
        # Add selected number of steps
        for i in range(steps):
            cot_prompt += step_templates[i] + '\n'
        
        cot_prompt += '\nNow, let\'s work through each step to arrive at the answer.'
        
        return cot_prompt

    def optimize_for_context_window(self, prompt: str = None, max_chars: int = 2000, preserve_examples: bool = True) -> Dict[str, Any]:
        import re
        
        original_length = len(prompt)
        
        if original_length <= max_chars:
            return {
                'optimized': prompt,
                'original_length': original_length,
                'optimized_length': original_length,
                'reduction_percentage': 0.0,
                'removed_elements': []
            }
        
        # Track what we remove
        removed = []
        optimized = prompt
        
        # Remove redundant whitespace
        optimized = re.sub(r'\s+', ' ', optimized).strip()
        if len(optimized) < len(prompt):
            removed.append('redundant whitespace')
        
        # Remove filler words if still too long
        if len(optimized) > max_chars:
            filler_words = [
                r'\b(basically|actually|really|very|quite|rather|somewhat|fairly)\b',
                r'\b(in order to)\b',
                r'\b(the fact that)\b',
                r'\b(it is important to note that)\b'
            ]
            for pattern in filler_words:
                if len(optimized) > max_chars:
                    new_optimized = re.sub(pattern, '', optimized, flags=re.IGNORECASE)
                    if len(new_optimized) < len(optimized):
                        optimized = re.sub(r'\s+', ' ', new_optimized).strip()
                        removed.append('filler words')
        
        # Remove examples if needed and not preserving
        if not preserve_examples and len(optimized) > max_chars:
            example_pattern = r'(Example:.*?\.)|(For example.*?\.)|(e\.g\..*?\.)'
            new_optimized = re.sub(example_pattern, '', optimized, flags=re.IGNORECASE)
            if len(new_optimized) < len(optimized):
                optimized = re.sub(r'\s+', ' ', new_optimized).strip()
                removed.append('examples')
        
        # Truncate with ellipsis if still too long
        if len(optimized) > max_chars:
            optimized = optimized[:max_chars-3] + '...'
            removed.append('truncated end')
        
        reduction_pct = ((original_length - len(optimized)) / original_length * 100) if original_length > 0 else 0
        
        return {
            'optimized': optimized,
            'original_length': original_length,
            'optimized_length': len(optimized),
            'reduction_percentage': round(reduction_pct, 1),
            'removed_elements': removed
        }


_toolset = GeneratedToolset()

@mcp.tool()
def enhance_prompt(prompt: str = None, target_model: str = 'general', style: str = 'detailed') -> Dict[str, str]:
    """Enhance a basic prompt with better structure, clarity, and specificity"""
    return _toolset.enhance_prompt(prompt, target_model, style)

@mcp.tool()
def add_examples(prompt: str = None, num_examples: int = 2) -> str:
    """Add relevant examples to a prompt to improve AI understanding"""
    return _toolset.add_examples(prompt, num_examples)

@mcp.tool()
def add_constraints(prompt: str = None, word_limit: int = 0, format_type: str = 'paragraph', tone: str = 'formal') -> str:
    """Add specific constraints and requirements to a prompt"""
    return _toolset.add_constraints(prompt, word_limit, format_type, tone)

@mcp.tool()
def create_chain_of_thought(prompt: str = None, steps: int = 3) -> str:
    """Convert a prompt into a chain-of-thought reasoning format"""
    return _toolset.create_chain_of_thought(prompt, steps)

@mcp.tool()
def optimize_for_context_window(prompt: str = None, max_chars: int = 2000, preserve_examples: bool = True) -> Dict[str, Any]:
    """Optimize a prompt to fit within token/character limits while preserving meaning"""
    return _toolset.optimize_for_context_window(prompt, max_chars, preserve_examples)


class GeneratedToolset:
    """Expose generated MCP tools as bound methods that can be iterated over."""
    _tool_names = ('enhance_prompt', 'add_examples', 'add_constraints', 'create_chain_of_thought', 'optimize_for_context_window')

    def __iter__(self):
        for tool_name in self._tool_names:
            yield getattr(self, tool_name)

    def enhance_prompt(self, prompt: str = None, target_model: str = 'general', style: str = 'detailed') -> Dict[str, str]:
        return enhance_prompt(prompt, target_model, style)

    def add_examples(self, prompt: str = None, num_examples: int = 2) -> str:
        return add_examples(prompt, num_examples)

    def add_constraints(self, prompt: str = None, word_limit: int = 0, format_type: str = 'paragraph', tone: str = 'formal') -> str:
        return add_constraints(prompt, word_limit, format_type, tone)

    def create_chain_of_thought(self, prompt: str = None, steps: int = 3) -> str:
        return create_chain_of_thought(prompt, steps)

    def optimize_for_context_window(self, prompt: str = None, max_chars: int = 2000, preserve_examples: bool = True) -> Dict[str, Any]:
        return optimize_for_context_window(prompt, max_chars, preserve_examples)


if __name__ == "__main__":
    # stdio transport for agent runtimes
    mcp.run()